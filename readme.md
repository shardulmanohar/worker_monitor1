**âš ï¸ Requires Python 3.10.16**
# ğŸ§  Worker Activity Monitoring System

A real-time, lightweight, standalone vision-based system to detect if a worker is **actively engaged**, **idle**, or **slouching**, using **MediaPipe Pose Estimation**. This system is optimized for low-cost hardware and designed for robust, real-world deployment.

---

## ğŸš€ Features

- ğŸ§ Pose-based movement detection using MediaPipe
- ğŸ¯ Joint-specific motion thresholds (palms, wrists, elbows, shoulders)
- ğŸ§  Posture classification using facial landmark angles
- â±ï¸ Idle state tracking with customizable timeout
- ğŸ§­ Region of Interest (ROI) masking (configurable)
- âš¡ Optimized for CPU-only environments (Raspberry Pi & laptops)
- ğŸ§° YAML-based configuration for full customizability
- ğŸ”Œ Auto webcam fallback if video path is not given

---

## ğŸ“ Project Structure

```
worker-monitor/
â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ config_reader.py       # Loads and validates config.yaml
â”‚   â”œâ”€â”€ config.yaml            # All settings in one place
â”œâ”€â”€ main.py                    # Main application script
â”œâ”€â”€ requirements.txt           # Python dependencies
â””â”€â”€ README.md                  # You're here
```

---

## âš™ï¸ Configuration (`assets/config.yaml`)

```yaml
video_path: ""  # leave blank to use webcam

resize_width: 640
resize_height: 360

thresholds:
  palm: 0.01
  wrist: 0.01
  elbow: 0.02
  shoulder: 0.03

angles:
  upright: [124.1, 117.4, 125.8]
  slouching: [143.1, 94.4, 142.7]

idle_threshold_seconds: 1

roi:  # Optional. Leave unset for full-frame
  - [0, 0]
  - [640, 0]
  - [640, 360]
  - [0, 360]
```

---

## ğŸ› ï¸ Configuration Parameters Explained

| Key                       | Type       | Description                                                                 |
|--------------------------|------------|-----------------------------------------------------------------------------|
| `video_path`             | string     | Path to the input video. Leave empty (`""`) to use the default webcam.     |
| `resize_width`           | integer    | Width to resize each frame for processing. Reduces load, improves speed.   |
| `resize_height`          | integer    | Height to resize each frame for processing.                                |
| `thresholds.palm`        | float      | Minimum movement (normalized) to count palm as active. Lower = more sensitive. |
| `thresholds.wrist`       | float      | Movement threshold for wrist joints.                                       |
| `thresholds.elbow`       | float      | Movement threshold for elbows.                                             |
| `thresholds.shoulder`    | float      | Movement threshold for shoulders.                                          |
| `angles.upright`         | list[float]| 3 angles representing upright head posture using facial landmarks.         |
| `angles.slouching`       | list[float]| 3 angles representing slouched head posture using facial landmarks.        |
| `idle_threshold_seconds` | float      | Time (in seconds) before a person is considered idle.                      |
| `roi`                    | list[list] | List of four [x, y] points defining a polygon ROI. Optional. Full frame is used if missing. |

---

## ğŸ“¦ Installation

```bash
pip install -r requirements.txt
python main.py
```
## ğŸ§  Detection Logic (How It Works)

The system determines a workerâ€™s activity status using a **hierarchical fallback model**:

1. **Fine joint motion detection (Palms â†’ Wrists)**
   - If either palm or wrist shows movement above the threshold â†’ status is **Working**

2. **Mid joint motion (Elbows)**
   - If wrists are not visible  elbows are checked next

3. **Coarse joint motion (Shoulders)**
   - If elbows are not visible shoulders are used as fallback

4. **Posture estimation via facial angles**
   - If shoulders are also still or invisible, the system uses face landmark angles to determine the pose: (**If elbows or hands are visible pose detection is not used**)
     - **Upright** â†’ Working
     - **Slouching** â†’ Slouching
     - Unclear/low-confidence â†’ Idle

5. **Idle time tracking**
   - If no sufficient activity is detected for `idle_threshold_seconds`, the worker is considered **Idle**

âœ… This logic mimics real-world expectations â€” if finer hand motions canâ€™t be seen, broader body or head posture is used as a fallback.

---

## ğŸ’¡ Design Choices

### âœ… Why MediaPipe instead of custom TFLite/ONNX model?

MediaPipe Pose is built on top of **TFLite models optimized by Google**, and delivers:
- Real-time, low-latency joint tracking
- Proven efficiency on low-end CPUs
- No training required â€” ready-to-deploy
> âœ… This satisfies the assignment's instruction to use TFLite or ONNX models while focusing on system design.

---

### âŒ Why Not Grayscale?

Grayscale would reduce input size, but was excluded because:
- MediaPipe Pose **requires RGB input**
- Grayscale would reduce accuracy or cause detection failure

âœ… Frame resizing and ROI masking were used instead for optimization.

---

### âŒ Why Not Background Removal?

While background removal is useful visually, it was excluded because:
- It adds heavy computational overhead
- ROI already ensures spatial focus
- Real-time performance was prioritized on limited hardware

---

## ğŸ§  Future Considerations

If extended for production use, the following could be considered:
- Support for detecting multiple workers simultaneously
- Optional alerting for prolonged inactivity
- Logging and reporting of activity timeline

---

## ğŸ“ License

MIT License â€” Use it, build on it, make it yours.

---

Made with ğŸ› ï¸ for vision-based workplace intelligence.
